{"cells":[{"cell_type":"markdown","metadata":{"id":"tb9EIYAir7vM"},"source":["# <font color='orange'><b>LORAë¥¼ í™œìš©í•œ LLM fine-tuning with Ko-PlatypusğŸ¥®</b></font>\n","\n","<img src = \"https://drive.google.com/uc?id=1OjplFXkW2KzgFZeGwsV1wAWR6oeIiIv2\" height=512, width=512>  \n","[Ko-platypus](https://github.com/Marker-Inc-Korea/KO-Platypus)  "]},{"cell_type":"markdown","metadata":{"id":"lqCodfTcS_RC"},"source":["-------\n","## 1. Colab í™˜ê²½ì„¤ì •ğŸ‘¨â€ğŸ’»\n","- Colab Pro\n","- GPU A100 í™œìš©\n","\n","\n","## 2. Ko-Platypus ì‹¤ìŠµë‚´ìš©ğŸ“–\n","> ì´ë²ˆ ì‹¤ìŠµì½”ë“œì—ì„œ ë‹¤ë¤„ì§ˆ ë‚´ìš©ë“¤ì€ ë‹¤ìŒê³¼ ê°™ì´ 6ê°œë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤!  \n","  \n","- Code í™˜ê²½ì„¤ì •\n","- Hyperparameters in LLM\n","- <font color='orange'><b>LoRAğŸ”¥</b></font>\n","- Instruction input-output dataset\n","- <font color='orange'><b>LLM fine-tuningğŸ¤—</b></font> (with ko-openorca datasetğŸ³)\n","- <font color='yellow'><b>â­Model Uploadâ­</b></font>\n","\n","  \n","## 3. ì‹¤ìŠµì— ì´ìš©ë˜ëŠ” ë°ì´í„°ì…‹ê³¼ ëª¨ë¸ğŸ“–\n","- âœ…ë°ì´í„°: [kyujinpy/Open-platypus-Commercial](https://huggingface.co/datasets/kyujinpy/Open-platypus-Commercial)  \n","- âœ…ëª¨ë¸: [upstage/SOLAR-10.7B-v1.0](https://huggingface.co/upstage/SOLAR-10.7B-v1.0)    \n","  \n","   \n","## 4. ì°¸ê³ ìë£Œ\n","- â­[Platypus](https://github.com/arielnlee/Platypus)  \n","- â­[garage-bAInd/Open-Platypus](https://huggingface.co/datasets/garage-bAInd/Open-Platypus)  \n","- â­[KO-Platypus2-7B-exğŸ¥®](https://huggingface.co/kyujinpy/KO-Platypus2-7B-ex)\n","- [HuggingFace](https://huggingface.co/)  \n","- [KO-LLM LeaderBoard](https://huggingface.co/spaces/upstage/open-ko-llm-leaderboard)  \n","- [EN-LLM LeaderBoard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)\n"]},{"cell_type":"markdown","metadata":{"id":"vb3N62XRvnud"},"source":["--------\n","# ğŸ‘¨â€ğŸ’» HuggingFace ë¡œê·¸ì¸\n","> ë³¸ê²©ì ì¸ ì‹œì‘ì— ì•ì„œì„œ Huggingfaceì— íšŒì›ê°€ì…ì„ ì§„í–‰í•´ë³¼ê¹Œìš”?\n","\n","1. ì•„ë˜ì˜ ë§í¬ë¡œ ì ‘ì†í•˜ì—¬ íšŒì›ê°€ì…ì„ ì§„í–‰í•©ë‹ˆë‹¤.\n","  - ğŸ¤—https://huggingface.co/\n","\n","2. ìì‹ ì˜ Access tokenì„ ìƒì„±í•©ë‹ˆë‹¤.\n","  - âœ…(ë©”ì¸ í™”ë©´) ìš°ì¸¡ ìƒë‹¨ì˜ ìì‹ ì˜ í”„ë¡œí•„ì„ í´ë¦­í•œ í›„, `setting`ì„ ëˆ„ë¥¸ë‹¤.\n","  - âœ…(í”„ë¡œí•„ í™”ë©´) ì™¼ìª½ ì¹´í…Œê³ ë¦¬ì—ì„œ `Access Token`ì„ ëˆ„ë¥¸ë‹¤.\n","  - âœ…ì˜¤ë¥¸ìª½ì—ì„œ `New token` ëˆŒëŸ¬ì„œ `Role: read`ë¡œ ì„¤ì •í•œ í›„ ìì‹ ì˜ tokenì„ ìƒì„±í•œë‹¤.\n","  - âœ…ë‹¤ì‹œ í•œë²ˆ, `New token` ëˆŒëŸ¬ì„œ `Role: write`ë¡œ ì„¤ì •í•œ í›„ ìì‹ ì˜ tokenì„ ìƒì„±í•œë‹¤.\n","\n","3. ì½”ë“œì—ì„œ Huggingface login ì§„í–‰ì„ í•©ë‹ˆë‹¤.\n","  - â­`Role: read`ë¡œ ìƒì„±ëœ tokenì„ ë³µì‚¬ í•œ í›„, ì•„ë˜ì˜ `[...read_token...]` ë¶€ë¶„ì— ë¶™ì—¬ë„£ëŠ”ë‹¤.\n","```python\n","!huggingface-cli login --token [...read_token...]\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JrDD6zSIvaAl"},"outputs":[],"source":["###########################################\n","# 0. Huggingface login\n","\n","# READ token\n","!huggingface-cli login --token [...read_token...] # your code"]},{"cell_type":"markdown","metadata":{"id":"2SXk0puNOpQ7"},"source":["--------\n","# ğŸ˜ Colab í™˜ê²½ì„¤ì •\n","> ë³¸ê²©ì ì¸ ì‹œì‘ì— ì•ì„œì„œ colabì˜ í™˜ê²½ì„¤ì •ì„ ì§„í–‰í•´ë³¼ê¹Œìš”?\n","\n","ğŸ” LLMì„ í›ˆë ¨ì‹œí‚¤ê¸° ìœ„í•´ì„œ ì•„ë˜ì˜ ëª¨ë“ˆì„ í•„ìˆ˜ì ìœ¼ë¡œ ì„¤ì¹˜í•´ì•¼í•©ë‹ˆë‹¤!\n","- ğŸ¤—transformers: LLM fine-tuning ë° ì „ë°˜ì ì¸ ê¸°ëŠ¥\n","- ğŸ¤—bitsandbytes: bit ë‹¨ìœ„ë¡œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆëŠ” ê¸°ëŠ¥\n","- ğŸ¤—accelerate: GPU ê°€ì†\n","- ğŸ”¥loralib: LoRA ì„¸íŒ…\n","- ğŸ¤—datasets: ë°ì´í„°ì…‹ í™œìš©\n","- ğŸ’peft: Parameter Efficient Fine Tuning ì ìš©\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NRx1ZaJOrtOz"},"outputs":[],"source":["###########################################\n","# 1-1. êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tS43LmbkUBCG"},"outputs":[],"source":["###########################################\n","# 1-2. í”„ë¡œì íŠ¸ í´ë” ë§Œë“¤ê¸°\n","\n","import os\n","os.makedirs('/content/drive/MyDrive/FastCampus-LLM', exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L92Xa0AwH1cz"},"outputs":[],"source":["%cd /content/drive/MyDrive/FastCampus-LLM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z72x_0sBUkNo"},"outputs":[],"source":["##########################################\n","# 1-3. ëª¨ë“ˆ ë‹¤ìš´\n","\n","!pip install bitsandbytes==0.41.1\n","!pip install accelerate==0.21.0\n","!pip install appdirs\n","!pip install loralib\n","!pip install black black[jupyter]\n","!pip install datasets\n","!pip install fire\n","!pip install git+https://github.com/huggingface/peft\n","!pip install transformers==4.34.1\n","!pip install sentencepiece sentence_transformers\n","!pip install scipy numpy scikit-learn pandas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxwVD1IVVmez"},"outputs":[],"source":["###########################################\n","# 1-4. ì„¤ì¹˜ëœ ëª¨ë“ˆ ë¦¬ìŠ¤íŠ¸ í™•ì¸í•˜ê¸°\n","\n","!pip list"]},{"cell_type":"markdown","metadata":{"id":"GtHstE0tWJrm"},"source":["--------\n","# ğŸ˜ ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f6-72g-XWINm"},"outputs":[],"source":["###########################################\n","# 2-1. ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°\n","\n","import os\n","import os.path as osp\n","import sys\n","import fire\n","import json\n","from typing import List, Union\n","\n","import torch\n","from torch.nn import functional as F\n","\n","import transformers\n","from transformers import TrainerCallback, TrainingArguments, TrainerState, TrainerControl\n","from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR\n","from transformers import LlamaForCausalLM, LlamaTokenizer\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","from datasets import load_dataset\n","\n","from peft import (\n","    LoraConfig,\n","    get_peft_model,\n","    prepare_model_for_int8_training,\n","    set_peft_model_state_dict\n",")\n","from peft import PeftModel"]},{"cell_type":"markdown","metadata":{"id":"upTfYsRNg7Dj"},"source":["--------\n","# ğŸ¤— Base Model (LLM)\n","- ìš°ë¦¬ê°€ í•´ë‹¹ ì‹¤ìŠµì½”ë“œì—ì„œ ì´ìš©í•  base LLM ëª¨ë¸ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤!\n","  - âœ…ëª¨ë¸: [upstage/SOLAR-10.7B-v1.0](https://huggingface.co/upstage/SOLAR-10.7B-v1.0)    \n","\n","## âœ”ï¸ Model Access í™•ì¸\n","> âœ…ëª¨ë¸ì„ ì´ìš©í•˜ê¸° ì „ì— accessê°€ ìˆëŠ”ì§€ ê¼­ í™•ì¸í•˜ì„¸ìš”!  \n","\n","<img src = \"https://drive.google.com/uc?id=1oACzT9OwEAundjhEOBdFI7-nV99OrIm8\">  \n","- ìœ„ì˜ ì‚¬ì§„ê³¼ ê°™ì€ <font color='#6069B9'><b>**âœ”ï¸access**</b></font> ë²„íŠ¼ì´ ìˆë‹¤ë©´ ê¼­ ëˆŒëŸ¬ì„œ ìŠ¹ì¸ì„ í•´ì•¼í•©ë‹ˆë‹¤!\n","- ì˜ˆë¥¼ ë“¤ì–´ meta-llamaì˜ ëª¨ë¸ì„ ê²½ìš°, ìŠ¹ì¸ì„ ë°›ì•„ì•¼ ì´ìš©ì´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì ë„ ì°¸ê³ í•´ì£¼ì„¸ìš”!  \n","  - ğŸ¤—í•´ë‹¹ ëª¨ë¸ì´ ì•„ë‹Œ ë‹¤ë¥¸ ëª¨ë¸ì„ base LLMìœ¼ë¡œ í™œìš©í•˜ì…”ë„ ë©ë‹ˆë‹¤!\n","  \n","#### ğŸ˜² Error Note\n","> Colabì—ì„œ ëª¨ë¸ì„ ë‹¤ìš´ ë°›ë‹¤ê°€ ì•„ë˜ì™€ ê°™ì€ ì—ëŸ¬ë¥¼ ë§Œë‚¬ë‹¤ë©´ í•œë²ˆ ë‹¤ìŒê³¼ ê°™ì´ í•´ê²°í•´ë³´ì„¸ìš”!\n","  \n","```python\n","ImportError: Using `load_in_8bit=True` requires Accelerate: `pip install\n","accelerate` and the latest version of bitsandbytes `pip install -i https://\n","test.pypi.org/simple/ bitsandbytes` or pip install bitsandbytes`  \n","```\n","- **âœ…Colabì˜ ëŸ°íƒ€ì„ ìœ í˜•ì´ A100ì¸ì§€ í™•ì¸.**"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"nfiPHh5Sh0kp"},"outputs":[],"source":["#@title ğŸ¤— Base model ì„ íƒí•˜ê¸°\n","device = 'auto' #@param {type: \"string\"}\n","base_LLM_model = 'upstage/SOLAR-10.7B-v1.0' #@param {type: \"string\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pIjvCtRJghoP"},"outputs":[],"source":["###########################################\n","# 3-1. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (~30ë¶„)\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    base_LLM_model,\n","    load_in_8bit=True, # LoRA\n","    #load_in_4bit=True, # Quantization Load\n","    torch_dtype=torch.float16,\n","    device_map=device)\n","\n","tokenizer = AutoTokenizer.from_pretrained(base_LLM_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o1_K5QbnzxUP"},"outputs":[],"source":["###########################################\n","# 3-2. BOS, EOS, PAD í† í° í™•ì¸\n","\n","# Check special token\n","bos = tokenizer.bos_token_id # ë¬¸ì¥ ì‹œì‘ í† í°\n","eos = tokenizer.eos_token_id # ë¬¸ì¥ ë í† í°\n","pad = tokenizer.pad_token_id # ë¬¸ì¥ íŒ¨ë”© í† í°\n","tokenizer.padding_side = \"right\" # íŒ¨ë”© ì˜¤ë¥¸ìª½\n","\n","print(\"BOS token:\", bos) # 1\n","print(\"EOS token:\", eos) # 2\n","print(\"PAD token:\", pad) # None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WOBun1kv0m_8"},"outputs":[],"source":["if (pad == None) or (pad == eos):\n","    tokenizer.pad_token_id = 0  # ë§Œì•½ íŒ¨ë”©ê°’ì´ ì—†ê±°ë‚˜ eosê°’ê³¼ ê°™ë‹¤ë©´,\n","print(\"length of tokenizer:\",len(tokenizer)) # 32000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C3ZSeYV0xf9Q"},"outputs":[],"source":["print(model)\n","print(type(model)) # ëª¨ë¸ì˜ íƒ€ì… í™•ì¸"]},{"cell_type":"markdown","metadata":{"id":"nmZIeJR3HCwN"},"source":["--------\n","# ğŸ’¡Hyperparameters setting\n","> ğŸ” LLM fine-tuningì—ì„œ ì¤‘ìš”í•œ <font color='green'><b>hyperpamaeter</b></font>ì— ëŒ€í•´ì„œ ì‚´í´ë³¼ê¹Œìš”?\n","\n","1. **ğŸ“–cutoff_len**\n","> ëª¨ë¸ì— ë“¤ì–´ê°ˆ **sequenceì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ì„¤ì •**í•˜ëŠ” parameter ì…ë‹ˆë‹¤!\n","\n","2. **ğŸ“–warmup_steps**\n","> warmup_stepsì€ ì²œì²œíˆ learning rateë¥¼ ì˜¬ë ¤ì„œ, í•™ìŠµì˜ ë¶ˆì•ˆì •ì„±ì„ ë°©ì§€í•´ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n","  \n","  - **Example)** learning rate (LR)ì„ 1e-2ë¡œ ì„¤ì •í–ˆë‹¤ë©´, LRì„ ì²˜ìŒì— ì´ˆê¹ƒê°’ë³´ë‹¤ ë‚®ê²Œ ì‹œì‘í•˜ì—¬ 100 stepì— ê±¸ì³ì„œ LRë¥¼ 1e-2ë¡œ ì˜¬ë¦°ë‹¤.\n","  \n","3. **ğŸ“–Optimizer**\n","> ìµœê·¼ì—ëŠ” Adamë³´ë‹¤ AdamWë¥¼ ë” ë§ì´ ì´ìš©í•˜ê³  ìˆì–´ìš”!  \n","> AdamWëŠ” Adamì— ë¹„í•´ì„œ ë” <font color='#ea7a7a'><b>general</b></font>í•˜ê²Œ ì„±ëŠ¥ì„ ë§Œë“¤ì–´ì£¼ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤!\n","  \n","  - Adam vs <font color='#ea7a7a'><b>**AdamW**</b></font>\n","\n","4. **ğŸ“–lr_scheduler**\n","> lr_schedulerëŠ” learning rateë¥¼ í›ˆë ¨í•˜ëŠ” ë™ì•ˆ ì¡°ì ˆí•´ì£¼ëŠ” ì˜µì…˜ì´ì˜ˆìš”!  \n","> ì•„ë˜ì˜ ëª©ë¡ì— ìˆëŠ” ì´ 3ê°€ì§€ í•¨ìˆ˜ ì˜µì…˜ì´ ê°€ì¥ ëŒ€í‘œì ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤!\n","  \n","  - constant\n","  - linear\n","  - <font color='#ea7a7a'><b>consine</b></font>\n","\n","5. **ğŸ“–Others**\n","> ğŸ˜Šê·¸ ì™¸ì— ì¤‘ìš”í•œ hyperparameter ì˜µì…˜ë“¤ì„ ëª¨ì•„ì„œ ì •ë¦¬í•´ë´¤ì–´ìš”!\n","\n","  - **â­Learning rate**\n","  - Batch size\n","  - weight_decay\n","  - max grad norm: gradient vector í¬ê¸° ì¡°ì ˆ (gradient clipping)"]},{"cell_type":"markdown","metadata":{"id":"zxrjlM6AdhJq"},"source":["## ğŸ‘¨â€ğŸ’» LoRA hyperparameters\n","> ğŸ” PEFTì˜ ëŒ€í‘œì ì¸ ë°©ë²•ë¡ ì¸ <font color='orange'><b>LoRAğŸ”¥</b></font>ì˜ <font color='green'><b>hyperpamaeter</b></font>ì— ëŒ€í•´ì„œ ì‚´í´ë´…ì‹œë‹¤!\n","\n","<img src = \"https://drive.google.com/uc?id=1ZoFUOPAyfWx80qk9Oa6b8oY0h1bJRoE0\" width=512>\n","\n","  -  <font color='orange'><b>**Lora_r**</b></font>: LoRA adapterì˜ ì°¨ì›ì„ ê²°ì •í•˜ëŠ” íŒŒë¼ë¯¸í„°\n","  - Lora_alpha: LoRA adapterì˜ scaling ê°’ì„ ê²°ì •í•˜ëŠ” íŒŒë¼ë¯¸í„°\n","  - Lora_dropout: LoRA adapterì˜ dropout íŒŒë¼ë¯¸í„°\n","  -  <font color='orange'><b>**Lora_target_modules**</b></font>: LoRA adapterë¥¼ ì ìš©í•  layers\n","  ```\n","Lora_target_modules ì¢…ë¥˜:\n","[\"embed_tokens\", \"lm_head\", \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", ...] # in llama2\n","  ```\n","> ğŸ” LoRAê°€ ì–´ë–»ê²Œ ì ìš©ë˜ëŠ”ì§€ ì½”ë“œë¡œ ì‚´í´ë³¼ê¹Œìš”?\n","  \n","  ```python\n","class Linear(nn.Linear, LoRALayer):\n","  # LoRA implemented in a dense layer\n","  def __init__(\n","          self,\n","          in_features: int,\n","          out_features: int,\n","          r: int = 0,\n","          lora_alpha: int = 1,\n","          lora_dropout: float = 0.,\n","          fan_in_fan_out: bool = False, # Set this to True if the layer to replace stores weight like (fan_in, fan_out)\n","          merge_weights: bool = True,\n","          **kwargs\n","      ):\n","          nn.Linear.__init__(self, in_features, out_features, **kwargs)\n","          LoRALayer.__init__(self, r=r, lora_alpha=lora_alpha, lora_dropout=lora_dropout,\n","                              merge_weights=merge_weights)\n","          self.fan_in_fan_out = fan_in_fan_out\n","          # ì‹¤ì œ í›ˆë ¨í•  íŒŒë¼ë¯¸í„°\n","          if r > 0:\n","              self.lora_A = nn.Parameter(self.weight.new_zeros((r, in_features)))\n","              self.lora_B = nn.Parameter(self.weight.new_zeros((out_features, r)))\n","              self.scaling = self.lora_alpha / self.r\n","              # Freezing the pre-trained weight matrix\n","              self.weight.requires_grad = False\n","          self.reset_parameters()\n","          if fan_in_fan_out:\n","            self.weight.data = self.weight.data.transpose(0, 1)\n","  ```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SphoNRsqHDNS"},"outputs":[],"source":["###########################################\n","# 5-1. í•˜ì´í¼ íŒŒë¼ë¯¸í„°\n","\n","# ë°ì´í„°ì…‹ê³¼ í›ˆë ¨ íšŸìˆ˜ì™€ ê´€ë ¨ëœ í•˜ì´í¼ íŒŒë¼ë¯¸í„°\n","batch_size = 16\n","num_epochs = 1\n","micro_batch = 1\n","gradient_accumulation_steps = batch_size // micro_batch\n","\n","# í›ˆë ¨ ë°©ë²•ì— ëŒ€í•œ í•˜ì´í¼ íŒŒë¼ë¯¸í„°\n","cutoff_len = 4096\n","lr_scheduler = 'cosine'\n","warmup_ratio = 0.06 # warmup_steps = 100\n","learning_rate = 4e-4\n","optimizer = 'adamw_torch'\n","weight_decay = 0.01\n","max_grad_norm = 1.0\n","\n","# LoRA config\n","lora_r = 16\n","lora_alpha = 16\n","lora_dropout = 0.05\n","lora_target_modules = [\"gate_proj\", \"down_proj\", \"up_proj\"]\n","\n","# Tokenizerì—ì„œ ë‚˜ì˜¤ëŠ” inputê°’ ì„¤ì • ì˜µì…˜\n","train_on_inputs = False\n","add_eos_token = False\n","\n","# Others\n","resume_from_checkpoint = False # !! ë§Œì•½ ëª¨ë¸ì„ ì´ì–´ì„œ í›ˆë ¨í•˜ê³  ì‹¶ë‹¤ë©´, './custom_LLM/checkpoint-[xxx]'ì™€ ê°™ì´ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤!\n","output_dir = './custom_LLM'"]},{"cell_type":"markdown","metadata":{"id":"PNDw8EcnDgy0"},"source":["--------\n","# ğŸ¤— Dataset Loading and formatting\n","> ğŸ‘¨â€ğŸ’» LLM fine-tuningì„ ìœ„í•œ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¤ê³  <font color='green'><b>instruction input-output</b></font>í˜•íƒœë¡œ ë§Œë“¤ì–´ ë´…ì‹œë‹¤!\n","\n","- ìš°ë¦¬ê°€ í•´ë‹¹ ì‹¤ìŠµì½”ë“œì—ì„œ ì´ìš©í•  ë°ì´í„°ì…‹ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤!\n","  - âœ…ë°ì´í„°: [kyujinpy/Open-platypus-Commercial](https://huggingface.co/datasets/kyujinpy/Open-platypus-Commercial)    "]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"uc6eJ15pD3oq"},"outputs":[],"source":["#@title ğŸ¤— Choose Dataset\n","dataset = 'kyujinpy/Open-platypus-Commercial' #@param {type: \"string\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t7Ywoq65DevA"},"outputs":[],"source":["###########################################\n","# 5-1. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ\n","\n","data = load_dataset(dataset)\n","print(data['train']) # ê°œìˆ˜: 19079"]},{"cell_type":"markdown","metadata":{"id":"SrsYtTRuof_W"},"source":["## ğŸ¤— Instruction input-output template\n","> ìš°ë¦¬ê°€ í™œìš©í•œ ë°ì´í„°ëŠ” ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ì„ ê°–ê³  ìˆìŠµë‹ˆë‹¤!\n","   \n","- âœ…Inputì´ ìˆëŠ” example:  \n","  \n","```\n","Input:\n","ë‹¹ì‹ ì€ ì‚¬ëŒë“¤ì´ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ì¸ê³µì§€ëŠ¥ ë¹„ì„œì…ë‹ˆë‹¤.\n","ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ê°€ëŠ¥í•œ í•œ ì¶©ì‹¤í•˜ê²Œ ëŒ€ë‹µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n","ë‹µë³€í•˜ëŠ” ë™ì•ˆ ë‹¨ê³„ë³„ë¡œ ìƒê°í•˜ê³  ë‹µë³€ì„ ì •ë‹¹í™”í•˜ì„¸ìš”.  \n","  \n","Instruction:\n","ì§ˆë¬¸ì…ë‹ˆë‹¤: ì‹œì† 60kmì˜ ì†ë„ë¡œ ë‹¬ë¦¬ëŠ” ê¸°ì°¨ê°€ 9ì´ˆ ë§Œì— ê¸°ë‘¥ì„ í†µê³¼í•©ë‹ˆë‹¤. ê¸°ì°¨ì˜ ê¸¸ì´ëŠ” ì–¼ë§ˆì…ë‹ˆê¹Œ?\n","ì˜µì…˜: (A) 287 (B) 699 (C) 677 (D) 168 (E) 150 ë¨¼ì € ìƒê°í•´ ë´…ì‹œë‹¤. ë¬´ì‘ìœ„ë¡œ ì¶”ë¡ í•´ ë´…ì‹œë‹¤:\n","  \n","Output:\n","ê¸°ì°¨ì˜ ê¸¸ì´ë¥¼ êµ¬í•˜ë ¤ë©´ ê¸°ì°¨ê°€ ê¸°ë‘¥ì„ í†µê³¼í•˜ëŠ” ë™ì•ˆ ì´ë™í•˜ëŠ” ê±°ë¦¬ë¥¼ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n","1ë‹¨ê³„: ê¸°ì°¨ì˜ ì†ë„ë¥¼ ì´ˆë‹¹ ë¯¸í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. 1km = 1000ë¯¸í„°, 1ì‹œê°„ = 3600ì´ˆ, ë”°ë¼ì„œ 60km/hr = (60 * 1000) / 3600 = 16.67m/s(ëŒ€ëµ).\n","2ë‹¨ê³„: ê¸°ì°¨ê°€ 9ì´ˆ ë™ì•ˆ ì´ë™í•œ ê±°ë¦¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ê±°ë¦¬ = ì†ë„ Ã— ì‹œê°„ ê±°ë¦¬ = 16.67m/s * 9ì´ˆ = 150ë¯¸í„°.\n","3ë‹¨ê³„: ê³„ì‚°ëœ ê±°ë¦¬ë¥¼ ì£¼ì–´ì§„ ì˜µì…˜ê³¼ ë¹„êµí•©ë‹ˆë‹¤.\n","ê³„ì‚°ëœ ê±°ë¦¬(150ë¯¸í„°)ì— ê°€ì¥ ê°€ê¹Œìš´ ì˜µì…˜ì€ ì˜µì…˜ (E) 150ì…ë‹ˆë‹¤.\n","ë”°ë¼ì„œ ì—´ì°¨ì˜ ê¸¸ì´ëŠ” ì•½ 150ë¯¸í„°ì…ë‹ˆë‹¤.\n","```\n","\n","  \n","- âœ…Inputì´ ì—†ëŠ” example:\n","\n","```\n","Instruction:\n","ì§ˆë¬¸ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤: ë‹¤ìŒ ê¸°ì‚¬ì— ëŒ€í•œ ê°ê´€ì‹ ë¬¸ì œë¥¼ ì‘ì„±í•˜ì„¸ìš”: ê¸°ì‚¬: ê²¨ìš¸ì€ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚ ì§€ ì•Œê¸° ì–´ë µê³  ì‚¬ê³ ê°€ ë„ˆë¬´ ì‰½ê²Œ ì¼ì–´ë‚˜ê¸° ë•Œë¬¸ì— ìœ„í—˜í•©ë‹ˆë‹¤.\n","ì•ˆê°œê°€ ì–¸ë• ê¼­ëŒ€ê¸°ì—ì„œ ì—¬ëŸ¬ë¶„ì„ ê¸°ë‹¤ë¦¬ê³  ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë…¹ëŠ” ëˆˆ ë°‘ì— ì–¼ìŒì´ ìˆ¨ì–´ ìˆë‹¤ê°€ ìš´ì „ìë¥¼ ë„ë¡œ ë°–ìœ¼ë¡œ ë‚´ë³´ë‚´ë ¤ê³  ê¸°ë‹¤ë¦¬ê³  ìˆì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n","ë§ˆì£¼ ì˜¤ëŠ” ì°¨ê°€ ê°‘ìê¸° ë„ë¡œë¥¼ ê°€ë¡œì§ˆëŸ¬ ë¯¸ë„ëŸ¬ì§ˆ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ë¹™íŒê¸¸ ìš´ì „ì˜ ì²« ë²ˆì§¸ ê·œì¹™ì€ ë¶€ë“œëŸ½ê²Œ ìš´ì „í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n","ê°‘ì‘ìŠ¤ëŸ¬ìš´ ì›€ì§ì„ì€ ìë™ì°¨ë¥¼ ì œì–´í•˜ê¸° ë§¤ìš° ì–´ë µê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì°¨ë¥¼ ì¶œë°œí•˜ê±°ë‚˜ ì •ì§€í•  ë•Œë§ˆë‹¤, ì†ë„ë¥¼ ë†’ì´ê±°ë‚˜ ë‚®ì¶œ ë•Œë§ˆë‹¤ ê°€ëŠ¥í•œ í•œ ë¶€ë“œëŸ½ê³  ì²œì²œíˆ ìš´ì „í•´ì•¼ í•©ë‹ˆë‹¤.\n","ì˜† ì¢Œì„ì— ëœ¨ê±°ìš´ ì»¤í”¼ í•œ ì”ì„ ê°€ë“ ë“¤ê³  ìš´ì „í•œë‹¤ê³  ê°€ì •í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì»¤í”¼ë¥¼ ì—ì§€ë¥´ì§€ ì•Šë„ë¡ ìš´ì „í•˜ì„¸ìš”.\n","ë‘ ë²ˆì§¸ ê·œì¹™ì€ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚ ì§€ ì£¼ì˜ë¥¼ ê¸°ìš¸ì´ëŠ” ê²ƒì…ë‹ˆë‹¤. ì–¼ìŒì´ ë§ì„ìˆ˜ë¡ ë„ë¡œ ì•„ë˜ìª½ì„ ë” ì˜ ì‚´í´ì•¼ í•©ë‹ˆë‹¤.\n","ì°¨ë¥¼ ë¶€ë“œëŸ½ê²Œ ì •ì§€í•˜ëŠ” ë° ê±¸ë¦¬ëŠ” ì‹œê°„ì„ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”. ìƒê°ë³´ë‹¤ ë” ë¹¨ë¦¬ ìš´ì „í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì„ ê¸°ì–µí•˜ì„¸ìš”.\n","ì¼ë°˜ì ìœ¼ë¡œ ë„ë¡œê°€ ì –ì–´ ìˆì„ ë•ŒëŠ” í‰ì†Œ ì •ì§€ ê±°ë¦¬ì˜ ë‘ ë°°, ëˆˆì´ ìŒ“ì—¬ ìˆì„ ë•ŒëŠ” ì´ ê±°ë¦¬ì˜ ì„¸ ë°°, ë¹™íŒê¸¸ì—ì„œëŠ” ê·¸ë³´ë‹¤ ë” ë§ì€ ê±°ë¦¬ë¥¼ í™•ë³´í•˜ì„¸ìš”.\n","í•­ìƒ ì°¨ëŸ‰ì„ í†µì œí•˜ë ¤ê³  ë…¸ë ¥í•˜ë©´ ë¬¸ì œê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì •ë‹µì€\n","\n","Output:\n","ë¹™íŒê¸¸ ìš´ì „ ì‹œ ê°€ì¥ ì¤‘ìš”í•œ ê·œì¹™ì€ ë¬´ì—‡ì¸ê°€ìš”?\n","A) ìœ„í—˜ ì§€ì—­ì„ ë” ë¹¨ë¦¬ í†µê³¼í•˜ê¸° ìœ„í•´ ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.\n","B) ì ì¬ì  ìœ„í—˜ì„ í”¼í•˜ê¸° ìœ„í•œ ê°‘ì‘ìŠ¤ëŸ¬ìš´ ì›€ì§ì„\n","C) ë¶€ë“œëŸ½ê³  ë¶€ë“œëŸ½ê²Œ ìš´ì „í•˜ì„¸ìš”\n","D) ë°”ë¡œ ì• ë„ë¡œì—ë§Œ ì§‘ì¤‘í•˜ê¸°\n","```"]},{"cell_type":"markdown","metadata":{"id":"AbgxRlpzz9ms"},"source":["> ğŸ” Alpaca templateë¥¼ í™œìš©í•˜ì—¬ì„œ ìš°ë¦¬ê°€ ì´ìš©í•˜ê³ ì í•˜ëŠ” ë°ì´í„°ì…‹ì„ instruction input-output í˜•ì‹ìœ¼ë¡œ ì¬ì •ì˜í•´ë³¼ê¹Œìš”?\n","- [Alpaca github](https://github.com/tatsu-lab/stanford_alpaca)   \n","  \n","#### âœ…ì˜ì–´ ë²„ì „ template\n","```\n","{\n","    \"prompt_input\": \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n\",\n","    \"prompt_no_input\": \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Response:\\n\",\n","    \"response_split\": \"### Response:\"    \n","}\n","\n","```\n","   \n","#### âœ…í•œêµ­ì–´ ë²„ì „ template\n","```\n","{\n","    \"prompt_input\": \"ì•„ë˜ëŠ” ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ì§€ì¹¨ê³¼ ì¶”ê°€ ì…ë ¥ì„ ì œê³µí•˜ëŠ” ì…ë ¥ì´ ì§ì„ ì´ë£¨ëŠ” ì˜ˆì œì…ë‹ˆë‹¤. ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\\n\\n### ì§€ì¹¨:\\n{instruction}\\n\\n### ì…ë ¥:\\n{input}\\n\\n### ë‹µë³€:\\n\",\n","    \"prompt_no_input\" : \"ì•„ë˜ëŠ” ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ì§€ì¹¨ì…ë‹ˆë‹¤. ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\\n\\n### ì§€ì¹¨:\\n{instruction}\\n\\n### ë‹µë³€:\\n\",\n","    \"response_split\": \"### ë‹µë³€:\"\n","}\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NK6EyQexOTBj"},"outputs":[],"source":["###########################################\n","# 5-2. Instruction tuningì„ ìœ„í•œ template ì‘ì„±.\n","\n","instruct_template = {\n","    \"prompt_input\": \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n\",\n","    \"prompt_no_input\": \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Response:\\n\",\n","    \"response_split\": \"### Response:\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z8f63aofNTWP"},"outputs":[],"source":["###########################################\n","# 5-3. ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ëŠ” í´ë˜ìŠ¤\n","\n","class Prompter(object):\n","\n","    def __init__(self, verbose: bool = False):\n","        self.template = instruct_template\n","\n","    def generate_prompt(\n","        self,\n","        instruction: str,\n","        input: Union[None, str] = None,\n","        label: Union[None, str] = None,\n","    ) -> str:\n","\n","        if input: # input textê°€ ìˆë‹¤ë©´\n","            res = self.template[\"prompt_input\"].format(\n","                instruction=instruction, input=input\n","            )\n","        else:\n","            res = self.template[\"prompt_no_input\"].format(\n","                instruction=instruction\n","            )\n","\n","        if label:\n","            res = f\"{res}{label}\"\n","\n","        return res\n","\n","    def get_response(self, output: str) -> str:\n","        return output.split(self.template[\"response_split\"])[1].strip()\n","\n","prompter = Prompter()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dWdjgMS6Gi6x"},"outputs":[],"source":["###########################################\n","# 5-4. Token generation í•¨ìˆ˜\n","\n","def tokenize(prompt, add_eos_token=True):\n","    result = tokenizer(\n","        prompt,\n","        truncation=True,\n","        max_length=cutoff_len,\n","        padding=False,\n","        return_tensors=None,\n","    )\n","\n","    if (\n","        result[\"input_ids\"][-1] != tokenizer.eos_token_id\n","        and len(result[\"input_ids\"]) < cutoff_len\n","        and add_eos_token\n","    ):\n","\n","        result[\"input_ids\"].append(tokenizer.eos_token_id)\n","        result[\"attention_mask\"].append(1)\n","\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","\n","    return result\n","\n","def generate_and_tokenize_prompt(data_point):\n","    full_prompt = prompter.generate_prompt(\n","        data_point[\"instruction\"],\n","        data_point[\"input\"],\n","        data_point[\"output\"])\n","\n","    tokenized_full_prompt = tokenize(full_prompt)\n","    if not train_on_inputs:\n","\n","        user_prompt = prompter.generate_prompt(\n","            data_point[\"instruction\"], data_point[\"input\"])\n","\n","        tokenized_user_prompt = tokenize(\n","            user_prompt, add_eos_token=add_eos_token)\n","\n","        user_prompt_len = len(tokenized_user_prompt[\"input_ids\"])\n","\n","        if add_eos_token:\n","            user_prompt_len -= 1\n","\n","        tokenized_full_prompt[\"labels\"] = [\n","            -100\n","        ] * user_prompt_len + tokenized_full_prompt[\"labels\"][\n","            user_prompt_len:\n","        ]\n","    return tokenized_full_prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p-ncCWzWQr4h"},"outputs":[],"source":["###########################################\n","# 5-5. í›ˆë ¨ ì…‹ ë§Œë“¤ê¸° (~3ë¶„)\n","\n","val_data = None\n","train_data = data[\"train\"].shuffle() # random\n","train_data = train_data.map(generate_and_tokenize_prompt)"]},{"cell_type":"markdown","metadata":{"id":"v8RcQ-wiSr1N"},"source":["#### âœ…'prompt_input' example:\n","\n","```\n","ì•„ë˜ëŠ” ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ì§€ì¹¨ê³¼ ì¶”ê°€ ì…ë ¥ì„ ì œê³µí•˜ëŠ” ì…ë ¥ì´ ì§ì„ ì´ë£¨ëŠ” ì˜ˆì œì…ë‹ˆë‹¤. ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n","\n","### ì§€ì¹¨:\n","ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”: ì œëª©: ë‚´ê°€ ë³¸ ìµœì•…ì˜ ì˜í™” ë¦¬ë·°: ì´ê²ƒì€ ë‚´ê°€ ë³¸ ìµœì•…ì˜ ì˜í™”ì…ë‹ˆë‹¤... DVDë¥¼ êµ¬ì…í•˜ëŠ” ìœ ì¼í•œ ì´ìœ ëŠ” ì´ ì˜í™”ë¥¼ ë§Œë“  12ì‚´ì§œë¦¬ ê¼¬ë§ˆê°€ ì €ëŠ¥ì•„ ì œì‘ìì—ê²Œ íŒ”ì•„ë„˜ê¸´ ì§„ì§œ ê°ë…ì˜ ì½”ë©˜í„°ë¦¬ë¥¼ ê³µê°œí•˜ê¸° ìœ„í•´ì„œì…ë‹ˆë‹¤. ê°€ì¥ ì¢‹ì€ ë¶€ë¶„ì€ ë¹„ë””ì˜¤ ê²Œì„ í´ë¦½ì„ ì´ì–´ ë¶™ì¸ ê²ƒì„ ë³¼ ë•Œì˜€ì„ ê²ƒì…ë‹ˆë‹¤. ì´ ìƒí’ˆí‰ì€ ë¶€ì •ì ì¸ê°€ìš”?\n","ë‹µë³€:\n","\n","### ì…ë ¥:\n","ê·€í•˜ëŠ” ì§€ì‹œë¥¼ ë§¤ìš° ì˜ ë”°ë¥´ëŠ” ì¸ê³µì§€ëŠ¥ ë¹„ì„œì…ë‹ˆë‹¤. ìµœëŒ€í•œ ë§ì´ ë„ì™€ì£¼ì„¸ìš”.\n","\n","### ë‹µë³€:\n","ì˜ˆ, ì´ ì œí’ˆ ë¦¬ë·°ëŠ” ë¶€ì •ì ì…ë‹ˆë‹¤.</s>\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8NCt1X--S1Hv"},"source":["#### âœ…'prompt_no_input' example:\n","\n","```\n","ì•„ë˜ëŠ” ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” ì§€ì¹¨ì…ë‹ˆë‹¤. ìš”ì²­ì„ ì ì ˆíˆ ì™„ë£Œí•˜ëŠ” ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n","\n","### ì§€ì¹¨:\n","x+y = 10$, $2x+y = 13$ì´ ì£¼ì–´ì¡Œì„ ë•Œ, $x^2-y^2$ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.\n","\n","### ë‹µë³€:\n","x^2-y^2$ë¥¼ í’€ë ¤ë©´ $x$ì™€ $y$ì˜ ê°’ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤. ì£¼ì–´ì§„ ë°©ì •ì‹ì„ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ ì¤‘ í•˜ë‚˜ë¥¼ ì œê±°í•˜ê³  ë‹¤ë¥¸ ë³€ìˆ˜ë¥¼ í’€ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ë°©ì •ì‹ì„ ë‘ ë²ˆì§¸ ë°©ì •ì‹ì—ì„œ ë¹¼ë©´ $2x+y - (x+y) = 13-10$ì´ ë‚˜ì˜¤ë©°, ì´ëŠ” $x = 3$ìœ¼ë¡œ ë‹¨ìˆœí™”ë©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì²« ë²ˆì§¸ ë°©ì •ì‹ì„ ì‚¬ìš©í•˜ì—¬ $x = 3$ì„ ëŒ€ì…í•˜ë©´ $3+y = 10$ì„ ì–»ì„ ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” $y = 7$ì´ë¼ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ì œ $x = 3$ê³¼ $y = 7$ì„ ì–»ì—ˆìœ¼ë¯€ë¡œ ì´ë¥¼ $x^2-y^2$ë¡œ ëŒ€ì…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ $3^2-7^2 = 9-49 = -40$ì´ ë©ë‹ˆë‹¤.</s>\n","```"]},{"cell_type":"markdown","metadata":{"id":"LByHr8qpRk_8"},"source":["--------\n","# ğŸ¤— Apply LoRA config\n","> â—ìš°ë¦¬ê°€ í›ˆë ¨ì— ì´ìš©í•  base LLMì— LoRAë¥¼ ì ìš©í•´ë´…ì‹œë‹¤!â—"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6M37ePijRGws"},"outputs":[],"source":["###########################################\n","# 6-1. LoRA config ì •ì˜\n","\n","config = LoraConfig(\n","    r=lora_r,\n","    lora_alpha=lora_alpha,\n","    target_modules=lora_target_modules,\n","    lora_dropout=lora_dropout,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CMB2WzT0SfGM"},"outputs":[],"source":["###########################################\n","# 6-2. Model with LoRA\n","\n","model = prepare_model_for_int8_training(model)\n","model = get_peft_model(model, config) # Applying LoRA"]},{"cell_type":"markdown","metadata":{"id":"zFEsYeMYTsUf"},"source":["--------\n","# â­ LLM fine-tuning\n","> ğŸ¥° ë“œë””ì–´ LLM fine-tuningì„ ìœ„í•œ ì¤€ë¹„ê°€ ëª¨ë‘ ëë‚¬ìŠµë‹ˆë‹¤! í•œë²ˆ ëª¨ë¸ì„ ëŒë ¤ë³¼ê¹Œìš”?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4tmSdPXhStNA"},"outputs":[],"source":["###########################################\n","# 7-1. ë§Œì•½ ì´ì „ì— ëŒë ¸ë˜ ëª¨ë¸ì„ ê°€ì ¸ì˜¨ë‹¤ë©´, ì•„ë˜ì˜ ì½”ë“œ ì‹¤í–‰\n","\n","if resume_from_checkpoint:\n","    checkpoint_name = os.path.join(\n","        resume_from_checkpoint, \"pytorch_model.bin\"\n","    )  # All checkpoint\n","\n","    if not os.path.exists(checkpoint_name):\n","        checkpoint_name = os.path.join(\n","            resume_from_checkpoint, \"adapter_model.bin\"\n","        )  # only LoRA model\n","        resume_from_checkpoint = (\n","            True\n","        ) # kyujin: I will use this checkpoint\n","\n","    if os.path.exists(checkpoint_name):\n","        print(f\"Restarting from {checkpoint_name}\")\n","        adapters_weights = torch.load(checkpoint_name)\n","        set_peft_model_state_dict(model, adapters_weights)\n","\n","    else:\n","        print(f\"Checkpoint {checkpoint_name} not found\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DtZpAMd1TlMV"},"outputs":[],"source":["###########################################\n","# 7-2. Trainer class ì •ì˜\n","\n","trainer = transformers.Trainer(\n","        model=model,\n","        train_dataset=train_data,\n","        eval_dataset=val_data,\n","        args=transformers.TrainingArguments( # í›ˆë ¨ì— ì´ìš©ë  í•˜ì´í¼íŒŒë¼ë¯¸í„°\n","            per_device_train_batch_size = micro_batch,\n","            gradient_accumulation_steps = gradient_accumulation_steps,\n","            warmup_ratio=warmup_ratio,\n","            num_train_epochs=num_epochs,\n","            learning_rate=learning_rate,\n","            fp16=True,\n","            logging_steps=1,\n","            optim=\"adamw_torch\",\n","            evaluation_strategy=\"no\",\n","            save_strategy=\"steps\",\n","            max_grad_norm = max_grad_norm,\n","            save_steps = 30, # you can change!\n","            lr_scheduler_type=lr_scheduler,\n","            output_dir=output_dir,\n","            save_total_limit=2,\n","            load_best_model_at_end=False,\n","            ddp_find_unused_parameters=False,\n","            group_by_length = False\n","        ),\n","        data_collator=transformers.DataCollatorForSeq2Seq(\n","            tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n","        ),\n","    )\n","\n","model.config.use_cache = False\n","model.print_trainable_parameters() # í›ˆë ¨í•˜ëŠ” íŒŒë¼ë¯¸í„°ì˜ % ì²´í¬\n","\n","if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n","    model = torch.compile(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DX8RW5YPUxWY"},"outputs":[],"source":["###########################################\n","# 7-3. Training (fine-tuning)\n","\n","## í›ˆë ¨ì‹œê°„ì´ ë§ì´ ì†Œìš”ë©ë‹ˆë‹¤! (~12h)\n","## ë§Œì•½ ì¤‘ê°„ì— colabì´ ëŠê¸´ë‹¤ë©´, checkpointë¥¼ ì´ìš©í•´ì„œ ë‹¤ì‹œ í›ˆë ¨í•˜ì„¸ìš”!\n","### ë§Œì•½ ê°œì¸ì ì¸ GPU ìì›ì´ ìˆë‹¤ë©´, ê°œì¸ ì„œë²„ë‚˜ ì»´í“¨í„°ì—ì„œ í›ˆë ¨ì‹œí‚¤ëŠ” ê²ƒì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤!\n","\n","torch.cuda.empty_cache()\n","trainer.train(resume_from_checkpoint=resume_from_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ad0OAYkR0TtG"},"outputs":[],"source":["###########################################\n","# 7-4. ëª¨ë¸ ì €ì¥\n","\n","model.save_pretrained(output_dir)\n","model_path = os.path.join(output_dir, \"pytorch_model.bin\")\n","torch.save({}, model_path)\n","tokenizer.save_pretrained(output_dir)"]},{"cell_type":"markdown","metadata":{"id":"8NNao1MNzUtB"},"source":["-------\n","# ğŸ¤— LoRA Adapter merge\n","> ğŸ‰ ë“œë””ì–´ LLM fine-tuningì´ ëë‚¬ìŠµë‹ˆë‹¤! ì—¬ê¸°ê¹Œì§€ ì˜¤ì‹œëŠë¼ ì •ë§ ê³ ìƒí•˜ì…¨ìŠµë‹ˆë‹¤!! ğŸ‰  \n","> ğŸ” ì´ì œ í›ˆë ¨í•œ LoRA layerë¥¼ ê¸°ì¡´ base LLMì— ë¶™ì—¬ì„œ ì €ì¥í•´ë³¼ê¹Œìš”!?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LRcka4btzTMO"},"outputs":[],"source":["###########################################\n","# 8-1. í›ˆë ¨ëœ LoRA layerì™€ base LLM ë³‘í•©(merge)\n","\n","torch.cuda.empty_cache()\n","\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    base_LLM_model,\n","    return_dict = True,\n","    torch_dtype=torch.float16,\n","    device_map=device)\n","\n","model = PeftModel.from_pretrained(base_model, output_dir, device)\n","model = model.merge_and_unload() # Merge!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qe6w9jvnzTFz"},"outputs":[],"source":["###########################################\n","# 8-2. ì—¬ëŸ¬ë¶„ì˜ custom LLM ëª¨ë¸ ì €ì¥!\n","\n","final_save_folder = './custom_LLM_final'\n","\n","model.save_pretrained(final_save_folder)\n","tokenizer.save_pretrained(final_save_folder)"]},{"cell_type":"markdown","metadata":{"id":"n8ViOCSH_8Ha"},"source":["-------\n","# ğŸ¤— HuggingFaceì— ëª¨ë¸ ì—…ë¡œë“œ\n","> âœ”ï¸ë§ˆì§€ë§‰ìœ¼ë¡œ, Huggingfaceì— ìì‹ ì˜ ëª¨ë¸ì„ ì§ì ‘ ì—…ë¡œë“œë¥¼ í•´ë´…ì‹œë‹¤!\n","\n","1. ì½”ë“œì—ì„œ Huggingface login ì§„í–‰í•©ë‹ˆë‹¤.\n","  - HuggingFaceì— ë‹¤ì‹œ ì ‘ì†í•˜ì—¬, access token ì¹´í…Œê³ ë¦¬ ì ‘ì†í•œë‹¤.\n","  - â­`Role: write`ë¡œ ìƒì„±ëœ tokenì„ ë³µì‚¬ í•œ í›„, ì•„ë˜ì˜ `[...write_token...]` ë¶€ë¶„ì— ë¶™ì—¬ë„£ëŠ”ë‹¤.\n","```\n","!huggingface-cli login --token [...write_token...]\n","```\n","  - âœ…Huggingfaceì— ì ‘ì†í•˜ì—¬, ëª¨ë¸ì„ ì—…ë¡œë“œ í•  repoë¥¼ ìƒì„±í•œë‹¤.\n","    - âœ…ì‚¬ì „ì— ì œê³µëœ`README.md` íŒŒì¼ì„ ì´ìš©í•˜ì—¬ ìì‹ ì˜ model cardë¥¼ ì‘ì„±í•œë‹¤.\n","  - âœ…ì•„ë˜ì˜ ì½”ë“œë¥¼ ì´ìš©í•˜ì—¬ ëª¨ë¸ê³¼ tokenizerë¥¼ ì—…ë¡œë“œí•œë‹¤.\n","```\n","model = AutoModelForCausalLM.from_pretrained(\"./custom_LLM_final\")\n","model.push_to_hub(\"[...repo_name...]\", token=True)\n","tokenizer = AutoTokenizer.from_pretrained(\"./custom_LLM_final\")\n","tokenizer.push_to_hub(\"[...repo_name...]\", token=True)\n","```\n","    - `repo_name` ë¶€ë¶„ì— ìì‹ ì´ ë§Œë“  ëª¨ë¸ repo ì´ë¦„ì„ ë¶™ì—¬ë„£ëŠ”ë‹¤.\n","    - ë§Œì•½ colabì—ì„œ ëª¨ë¸ ì—…ë¡œë“œê°€ ì•ˆëœë‹¤ë©´, êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ ì§ì ‘ ë‹¤ìš´ ë°›ì•„ì„œ repoì— ì˜¬ë ¤ì£¼ëŠ” ë°©ë²•ì´ ìˆë‹¤.\n","\n","  \n","2. âœ”ï¸Huggingface repoì— ì—…ë¡œë“œ ëœ ëª¨ë¸ ì˜ˆì‹œ ì´ë¯¸ì§€  \n","<img src = \"https://drive.google.com/uc?id=1yiQv-SeN78H378oTO4UvzvEm4dG3mD0K\"\n","height = 512>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TtWH4V9nVfYl"},"outputs":[],"source":["###########################################\n","# 9-1. í—ˆê¹…í˜ì´ìŠ¤ ë¡œê·¸ì¸\n","\n","# WRITE token\n","!huggingface-cli login --token [...write_token...] # your code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S76GCggGzMD5"},"outputs":[],"source":["###########################################\n","# 9-2. ëª¨ë¸ ì—…ë¡œë“œ (~10ë¶„)\n","## ë¨¼ì €, í—ˆê¹…í˜ì´ìŠ¤ì— ëª¨ë¸ repoë¥¼ ë§Œë“  í›„ ì½”ë“œë¥¼ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤!\n","\n","model = AutoModelForCausalLM.from_pretrained(final_save_folder)\n","model.push_to_hub([...repo_name...], token=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nT3MeKo02vCd"},"outputs":[],"source":["###########################################\n","# 9-3. Tokenizer ì—…ë¡œë“œ\n","\n","tokenizer = AutoTokenizer.from_pretrained(final_save_folder)\n","tokenizer.push_to_hub([...repo_name...], token=True)"]},{"cell_type":"markdown","metadata":{"id":"28oGxX_x3EKS"},"source":["-------\n","# ğŸ¤— Huggingface LLM ë¦¬ë”ë³´ë“œ ì‹¤ìŠµ\n","> ğŸ‰ì—¬ê¸°ê¹Œì§€ ì—¬ëŸ¬ë¶„ë§Œì˜ custom LLMì„ ë§Œë“¤ê³  huggingfaceì— ì§ì ‘ ì˜¬ë¦¬ëŠ” ì‹¤ìŠµ ì§„í–‰í–ˆìŠµë‹ˆë‹¤!!ğŸ‰  \n","> ğŸ’¡ìì‹ ì´ ë§Œë“  ëª¨ë¸ì„ LLM ë¦¬ë”ë³´ë“œì— ì˜¬ë ¤ì„œ ì„±ëŠ¥í‰ê°€ë¥¼ ì§„í–‰í•˜ê³ , ë¶„ì„ì„ ê°™ì´ í•´ë´…ì‹œë‹¤!\n","\n","- [En-LLM ë¦¬ë”ë³´ë“œ](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)  \n","- [Ko-LLM ë¦¬ë”ë³´ë“œ](https://huggingface.co/spaces/upstage/open-ko-llm-leaderboard)   \n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"1ajjaAkbzRna7Udjf0WAH406jMULnYIY1","timestamp":1700589110156}]},"kernelspec":{"display_name":"Python 3.11.4 ('llama2')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.4"},"vscode":{"interpreter":{"hash":"650f3506fd3966bb017cc36532c1b7da23d4f3599ff501eaa18c43c672ed7c53"}}},"nbformat":4,"nbformat_minor":0}
