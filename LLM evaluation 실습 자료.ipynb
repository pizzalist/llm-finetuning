{"cells":[{"cell_type":"markdown","metadata":{"id":"2o5_-5jfVURK"},"source":["# 😎 Ko-LLM Evaluation Code\n","\n","## 1. Colab 환경설정👨‍💻\n","- Colab Pro\n","- GPU A100 활용\n","\n","## 2. 실습내용📖\n","- LLM을 평가하는 데이터셋 소개\n","- LM-evaluation-harness를 활용하여 <font color='yellow'><b>모델 성능 사전평가🤗</b></font>\n","\n","## 3. 참고자료\n","- [LM-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness)  "]},{"cell_type":"markdown","metadata":{"id":"c0FX6y0lK70K"},"source":["--------\n","# 👨‍💻 HuggingFace 로그인\n","> 본격적인 시작에 앞서서 Huggingface에 회원가입을 진행해볼까요?\n","\n","1. 아래의 링크로 접속하여 회원가입을 진행합니다.\n","  - 🤗https://huggingface.co/\n","\n","2. 자신의 Access token을 생성합니다.\n","  - ✅(메인 화면) 우측 상단의 자신의 프로필을 클릭한 후, `setting`을 누른다.\n","  - ✅(프로필 화면) 왼쪽 카테고리에서 `Access Token`을 누른다.\n","  - ✅오른쪽에서 `New token` 눌러서 `Role: read`로 설정한 후 자신의 token을 생성한다.\n","  - ✅다시 한번, `New token` 눌러서 `Role: write`로 설정한 후 자신의 token을 생성한다.\n","\n","3. 코드에서 Huggingface login 진행을 합니다.\n","  - ⭐`Role: read`로 생성된 token을 복사 한 후, 아래의 `[...read_token...]` 부분에 붙여넣는다.\n","```python\n","!huggingface-cli login --token [...read_token...]\n","```"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"6bAA6hW9Bquu"},"outputs":[{"ename":"NameError","evalue":"name 'ᄆ' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m###########################################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 0. 허깅페이스 로그\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mㅁ\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# READ token\u001b[39;00m\n\u001b[1;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuggingface-cli login --token \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhf_YFOlpHKCQxrjJtbgzTdvLRpSyolzxsbhkJ\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m # your code\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'ᄆ' is not defined"]}],"source":["###########################################\n","# 0. 허깅페이스 로그\n","\n","# READ token\n","!huggingface-cli login --token 'YOUR_KEY' "]},{"cell_type":"markdown","metadata":{"id":"HPh9CqWTLHm3"},"source":["--------\n","# 😎 Colab 환경설정\n",">본격적인 시작에 앞서서 colab의 환경설정을 진행해볼까요?\n","  \n","#### 🔎 LM-Harness-Evaluation은 아래의 github를 통해서 코드를 실행해야합니다!\n","- 🤗[EleutherAI/lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness)  \n","  - 📍만약 한국어 LLM을 대상으로 평가를 진행하고 싶다면 아래의 코드를 실행해야합니다!\n","  - 🤗[beomi/ko-lm-evaluation-harness](https://github.com/Beomi/ko-lm-evaluation-harness)   \n"]},{"cell_type":"markdown","metadata":{"id":"Nn97Scz37FeL"},"source":["#### 👨‍💻Github 다운 받는 방법!  \n","```\n","!git clone https://github.com/EleutherAI/lm-evaluation-harness\n","%cd ./lm-evaluation-harness\n","!pip install -e .\n","!pip install evaluate\n","```\n","- 📍만약 한국어 LLM을 평가하고 싶다면, 아래의 코드를 입력 해보세요!\n","```\n","!git clone https://github.com/Beomi/ko-lm-evaluation-harness\n","%cd ./ko-lm-evaluation-harness\n","!pip install -e .\n","!pip install evaluate\n","```"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"BVpmAP4VLJOW"},"outputs":[{"ename":"NameError","evalue":"name 'ᄆᄂᄋᄅ' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m###########################################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 1-3. 모듈 다운로드 (한국어 모델 평가)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mㅁㄴㅇㄹ\u001b[49m\n\u001b[1;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgit clone https://github.com/Beomi/ko-lm-evaluation-harness\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./ko-lm-evaluation-harness\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'ᄆᄂᄋᄅ' is not defined"]}],"source":["###########################################\n","# 1-3. 모듈 다운로드 (한국어 모델 평가)\n","!git clone https://github.com/Beomi/ko-lm-evaluation-harness\n","%cd ./ko-lm-evaluation-harness\n","!pip install -e .\n","!pip install evaluate"]},{"cell_type":"markdown","metadata":{"id":"capZoFC9LerH"},"source":["------\n","# 🤗 LLM Evaluation\n","\n","## 1. 📖 대표적인 Datasets\n","- 📍Hellaswag: **지시사항에 이어질** 알맞은 문장 생성 능력을 평가하는 데이터셋\n","- 📍Copa: **원인/결과**에 알맞은 문장 생성 능력을 평가하는 데이터셋\n","- 📍Boolq: 질문에 대한 **예/아니요** 답변 능력 평가을 평가하는 데이터셋\n","- 📍Sentineg: 문장에 대한 **긍/부정** 평가 능력을 평가하는 데이터셋\n","\n","  \n","## 2. Metric\n","- ✅Accuracy\n","- ✅F1-score (대표적으로 활용)\n","\n","\n","## 3. N-shot Evaluation\n","- 💎Zero-shot: 훈련 과정에서 배우지 않은 작업을 수행하는 것을 의미합니다!\n","- 💎Few-shot: 소수의 데이터셋을 학습한 후 작업을 수행하는 것을 의미합니다!\n","  \n","\n","## 4. 👨‍💻 Code Implementation\n","- ✅한국어 평가 코드\n","```python\n","!python main.py \\\n","    --model gpt2 \\\n","    --model_args pretrained = [...Custom_LLM...] \\\n","    --tasks [...Datasets...] \\\n","    --device cuda:0 \\\n","    --num_fewshot [...N-shot...]\n","```\n","\n","- ✅영어 평가 코드\n","```Python\n","!lm_eval --model hf \\\n","    --model_args pretrained=[...Custom_LLM...] \\\n","    --tasks [...Datasets...] \\\n","    --device cuda:0 \\\n","    --batch_size 8 \\\n","    --num_fewshot [...N-shot...]\n","```\n","\n","- Custom_LLM: 자신이 만든 LLM 모델의 `huggingface repo 이름`  \n","- Datasets\n","  - 영어: `hellaswag`, `copa`, `boolq`, `sentineg`  \n","  - 한국어: `kobest_hellaswag`, `kobest_copa`, `kobest_boolq`, `kobest_sentineg`\n","- N-shot: `0(zero-shot)`, `5`, `10`, `50`, ...\n","\n","  \n","## 5. ✅ Example result\n","- Using [Custom-KoLLM-13B-v1](https://huggingface.co/PracticeLLM/Custom-KoLLM-13B-v1)  \n","- Zero shot performace\n","  \n","|      Task      |Version| Metric |Value |   |Stderr|\n","|----------------|------:|--------|-----:|---|-----:|\n","|kobest_boolq    |      0|acc     |0.5021|±  |0.0133|\n","|                |       |macro_f1|0.3343|±  |0.0059|\n","|kobest_copa     |      0|acc     |0.7990|±  |0.0127|\n","|                |       |macro_f1|0.7987|±  |0.0126|\n","|kobest_hellaswag|      0|acc     |0.5020|±  |0.0224|\n","|                |       |acc_norm|0.5780|±  |0.0221|\n","|                |       |macro_f1|0.4994|±  |0.0225|\n","|kobest_sentineg |      0|acc     |0.7179|±  |0.0226|\n","|                |       |macro_f1|0.6984|±  |0.0238|"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ZUJEdSxfvVW"},"outputs":[],"source":["###########################################\n","# 2-0. task 종류 확인 (영어)\n","\n","!lm-eval --tasks list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LlaVCbp7fqnu"},"outputs":[],"source":["###########################################\n","# 2-1. Zero-shot 평가 (영어)\n","## About hellaswag, copa, boolq, mmlu\n","\n","!lm_eval --model hf \\\n","    --model_args pretrained=[...Custom_LLM...] \\\n","    --tasks hellaswag,copa,boolq,mmlu \\\n","    --device cuda:0 \\\n","    --batch_size 8 \\\n","    --num_fewshot 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iBc0APZNfqvB"},"outputs":[],"source":["###########################################\n","# 2-2. 5-shot 평가 (영어)\n","## About hellaswag, copa, boolq, mmlu\n","\n","!lm_eval --model hf \\\n","    --model_args pretrained=[...Custom_LLM...] \\\n","    --tasks hellaswag,copa,boolq,mmlu \\\n","    --device cuda:0 \\\n","    --batch_size 8 \\\n","    --num_fewshot 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2wLFcjBLfqxb"},"outputs":[],"source":["###########################################\n","# 2-3. 10-shot 평가 (영어)\n","## About hellaswag, copa, boolq, mmlu\n","\n","!lm_eval --model hf \\\n","    --model_args pretrained=[...Custom_LLM...] \\\n","    --tasks hellaswag,copa,boolq,mmlu \\\n","    --device cuda:0 \\\n","    --batch_size 8 \\\n","    --num_fewshot 10"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"W1vPn1Cb99y5"},"outputs":[{"ename":"IndentationError","evalue":"unexpected indent (3015890101.py, line 6)","output_type":"error","traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[1], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    --num_fewshot 0\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"]}],"source":["###########################################\n","# 2-4. Zero-shot 평가 (한국어)\n","## About hellaswag, copa, boolq, sentineg\n","\n","!python main.py \\\n","    --model gpt2 \\\n","    --model_args pretrained='meta-llama/Llama-2-7b-hf' \\\n","    --tasks kobest_hellaswag,kobest_copa,kobest_boolq,kobest_sentineg \\\n","    --device cuda:0 \\\n","    --num_fewshot 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YglVph9aD09v"},"outputs":[],"source":["###########################################\n","# 2-5. 5-shot 평가 (한국어)\n","## About hellaswag, copa, boolq, sentineg\n","\n","!python main.py \\\n","    --model gpt2 \\\n","    --model_args pretrained='letgoofthepizza/Llama-2-7b-hf-finetuned-open-korean-instructions' \\\n","    --tasks [...Datasets...] \\\n","    --device cuda:0 \\\n","    --num_fewshot 5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ALXs7iUn-7On"},"outputs":[],"source":["###########################################\n","# 2-6. 10-shot 평가 (한국어)\n","## About hellaswag, copa, boolq, sentineg\n","\n","!python main.py \\\n","    --model gpt2 \\\n","    --model_args pretrained=[...Custom_LLM...] \\\n","    --tasks [...Datasets...] \\\n","    --device cuda:0 \\\n","    --num_fewshot 10"]},{"cell_type":"markdown","metadata":{"id":"74LyWVw35K3y"},"source":["# 🤗 실습코드 마무리!\n","> 여기까지 오신 여러분 너무나 고생 많으셨습니다😊   \n","> 우리는 <font color='orange'><b>Custom LLM 제작🔥</b></font>부터 <font color='orange'><b>evaluation🔥</b></font>까지 진행했습니다!   \n","  \n","> ❗이어지는 강의에서는 **LLM 리더보드**에 직접 자신의 모델을 올리고 여러 모델과 성능비교 및 분석하는 시간을 가져보도록 하겠습니다❗\n","\n","## 콘텐츠 라이선스\n","\n","저작권 : <font color='blue'> <b> ©2023 by Upstage X fastcampus Co., Ltd. All rights reserved.</font></b>\n","\n","<font color='red'><b>WARNING</font> : 본 교육 콘텐츠의 지식재산권은 업스테이지 및 패스트캠퍼스에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다. </b>"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1-g790kFN7RyS1beboLrl7b3SCJ1L8ZaD","timestamp":1700938670197},{"file_id":"1HOCteGprplUQdHBuPrVVeZQEdpShmaWc","timestamp":1700927132151},{"file_id":"10orl9Z8B99Qta3Yug5s9quFs49vULdzn","timestamp":1692533780025},{"file_id":"1CfhOlMsUaPCfNwMy-bad4uKIMyrhZ6lu","timestamp":1692127809299},{"file_id":"183I6BovpuGabKouUyThhu77NjxcWIYPO","timestamp":1692117771433},{"file_id":"1U7ON76oXw6Glz2BflnshuaOEuJF1A2z9","timestamp":1692024495933},{"file_id":"1_TEJopoN7a4jeDOQZ0Dse4fIEXUFtYRC","timestamp":1691999868384},{"file_id":"19Tjtwdd2bz0twOoWaxxyAcOVySM_Kj6O","timestamp":1690992147659},{"file_id":"1be0mX8QQ77vczL5PW-15Acu_OxZCF7o4","timestamp":1690985822915},{"file_id":"1bxI8SEJBOK2cfa_sLi6mKOrbRuDNPM2e","timestamp":1690114955968}]},"kernelspec":{"display_name":"Python 3.11.4 ('llama2')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"vscode":{"interpreter":{"hash":"650f3506fd3966bb017cc36532c1b7da23d4f3599ff501eaa18c43c672ed7c53"}}},"nbformat":4,"nbformat_minor":0}
